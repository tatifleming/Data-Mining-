{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FA084_1s2021_Aula05_vALUNO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatifleming/Data-Mining-/blob/main/FA084_1s2021_Aula05_vALUNO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S0NSCgk0EOV"
      },
      "source": [
        "# Scikit-Learn\n",
        "\n",
        "*   Biblioteca de 'Aprendizado de Máquina' (*'Machine Learning'*) para Python.\n",
        "*   A estrutura do Scikit-Learn é por meio vários componentes, a partir dos quais se importam as bibliotecas relevantes àquele componente.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diBYntehmarn"
      },
      "source": [
        "# Importação de TODAS as bibliotecas que serão utilizadas\n",
        "\n",
        "# Gerais\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scikit-Learn\n",
        "\n",
        "# Conjunto Treino/Teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Normalização (MinMax e Z-Score)\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Técnica (KNN para Classificação)\n",
        "\n",
        "\n",
        "# Técnica (Árvore de Decisão para Classificação)\n",
        "\n",
        "\n",
        "# Otimização dos hiperparâmetros\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "# Métricas para Classificação - Matriz de Confusão, Relatório Geral, Acurácia, Precisão, Recall e F1-Score\n",
        "\n",
        "\n",
        "# Importar 'DummyClassifier' do componente 'dummy' do sklearn\n",
        "\n",
        "# Para visualização da Árvore\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lP3xhQYRGj3"
      },
      "source": [
        "# Dataset **'Qualidade de Vinho Tinto'** (o mesmo da Aula 3) - Problema de CLASSIFICAÇÃO\n",
        "\n",
        "(Versão editada do conjunto original do Kaggle)\n",
        "\n",
        "Fonte: Kaggle  \n",
        "https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009\n",
        "\n",
        "\n",
        "Fazer download neste link: http://bit.ly/AnaliseDados-QualidadeVinhoDataset\n",
        "\n",
        "### Consideraremos as notas 'quality' com as seguintes representações:\n",
        "\n",
        "* Vinhos com notas superiores a 5 são bons: Notas 6, 7 e 8\n",
        "* Vinhos com notas iguais ou inferiores a 5 são ruins: Notas 3, 4 e 5\n",
        "\n",
        "### Atribuiremos Classe 1 para vinhos bons e Classe 0 para vinhos ruins\n",
        "\n",
        "\n",
        "* Usaremos KNN e Árvore de Decisão\n",
        "* Construiremos uma Tabela (DataFrame) com os Resultados, que nos permitirá comparar os resultados obtidos com as duas técnicas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLKoadJOGay4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "bdf857d2-1541-422e-e4fb-8fe993ec1f2b"
      },
      "source": [
        "# Leitura do conjunto de dados\n",
        "df = pd.read_csv('winequality-red.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
              "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
              "3           11.2              0.28         0.56  ...       0.58      9.8        6\n",
              "4            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpljel2IG3r1"
      },
      "source": [
        "# Criar atributo 'good_quality', no qual '1' é bom (quality 6 ou maior) e '0' é ruim (quality 5 ou menor)\n",
        "# Utilizar formato compacto 'list comprehension'\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87tAjyyAH1ls",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "da5a7405-98fb-48ea-e83d-f99a171acdf6"
      },
      "source": [
        "# Separar atributos preditores(X) do atributo meta (y)\n",
        "y = \n",
        "X = \n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-68e6dab83ed8>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    y =\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycAvzPZw5243"
      },
      "source": [
        "# Primeiras linhas dos atributos preditores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFKUVVpkHHgy"
      },
      "source": [
        "# Dividir Conjunto de dados em Treino/Test na proporção 70/30 (random_state = 2021)\n",
        "X_train, X_test, y_train, y_test = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EQI1_7Uus6y"
      },
      "source": [
        "# VERIFICAR DISTRIBUIÇÃO do atributo meta\n",
        "print(y.value_counts(normalize=True))\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(y_test.value_counts(normalize=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qENfLnF9q-cV"
      },
      "source": [
        "## Calcular o 'Dummy' para ter como base de comparação com os outros modelos\n",
        "\n",
        "* Iremos calcular 'Dummy' para TRÊS modelos:  \n",
        "  (1) SEM normalizar  \n",
        "  (2) Normalizando Min-Max e  \n",
        "  (3) Normalizando Z-Score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJa6PQzyI3Q5"
      },
      "source": [
        "## KNN\n",
        "\n",
        "* Iremos criar TRÊS modelos:  \n",
        "  (1) SEM normalizar  \n",
        "  (2) Normalizando Min-Max e  \n",
        "  (3) Normalizando Z-Score\n",
        "\n",
        "* Em todos os casos, otimizaremos o hiperparâmetro K:  \n",
        "  (1) GridSearchCV e  \n",
        "  (2) RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYKCI-GWJ5Rq"
      },
      "source": [
        "### 'Dummy' e KNN SEM normalizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olwyD95mrb3n"
      },
      "source": [
        "# Criar objeto definindo estratégia para estimativa e ajustar ao conjunto de treino\n",
        "dummy_SEM = \n",
        "\n",
        "# Fazer a predição no conjunto de teste utilizando o objeto definido e ajustado anteriormente\n",
        "y_pred_dummy = \n",
        "\n",
        "# Construir Matriz de Confusão (DataFrame) para 'Dummy'\n",
        "MatConf = \n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_dummy))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "acc_dummy_SEM = \n",
        "print('Acurácia: ',acc_dummy_SEM)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "prec_dummy_SEM = \n",
        "print('Precisão: ',prec_dummy_SEM)\n",
        "\n",
        "# Recall (recall_score)\n",
        "recall_dummy_SEM = \n",
        "print('Recall: ',recall_dummy_SEM)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "f1_score_dummy_SEM = \n",
        "print('F1 Score: ',round(f1_score_dummy_SEM,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "revsizq0tiXk"
      },
      "source": [
        "# Checar distribuição de valores em y_test\n",
        "y_test.value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDpQr8KmKNVu"
      },
      "source": [
        "#### Otimizar Hiperparâmetro K utilizando GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSd-EnYqIhj1"
      },
      "source": [
        "# Cronometrar o tempo de execução\n",
        "%%time\n",
        "\n",
        "# Passo 1: Definir a faixa do grid em que o hiperparâmetro vai variar\n",
        "# IMPORTANTE: Formato de 'dictionary' {'label':valor}\n",
        "faixa_K = {'n_neighbors':np.arange(1,20)}\n",
        "\n",
        "# Passo 2: Definir o objeto com a técnica e os parâmetros da otimização\n",
        "knn_gsearch_SEM = \n",
        "\n",
        "# Passo 3: Otimizar o objeto definido anteriormente no conjunto de dados\n",
        "knn_gsearch_SEM.fit()\n",
        "\n",
        "# Passo 4: Apresentar o melhor K (K quando se obteve o melhor resultado)\n",
        "opt_K = \n",
        "print(opt_K)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2G9Bhaev2-L"
      },
      "source": [
        "# Conhecer alguns outros componentes do objeto knn_gsearch_SEM\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPrcCVz6dyEH"
      },
      "source": [
        "# Otimizado o hiperparâmetro\n",
        "%%time\n",
        "# Passo 1: Criar um objeto e ajustar o objeto ao Conjunto de Treino, utilizando o hiperparâmetro ótimo\n",
        "knn_gsearch_SEM = \n",
        "\n",
        "# Passo 2: Fazer predição do modelo no Conjunto de Teste\n",
        "y_pred_gsearch_SEM = \n",
        "\n",
        "# Passo 3: Avaliar o modelo\n",
        "# Construir Matriz de Confusão (DataFrame)\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_gsearch_SEM, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_gsearch_SEM))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "knn_acc_gsearch_SEM = accuracy_score(y_test, y_pred_gsearch_SEM)\n",
        "print('Acurácia: ',knn_acc_gsearch_SEM)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "knn_prec_gsearch_SEM = precision_score(y_test, y_pred_gsearch_SEM)\n",
        "print('Precisão: ',knn_prec_gsearch_SEM)\n",
        "\n",
        "# Recall (recall_score)\n",
        "knn_recall_gsearch_SEM = recall_score(y_test, y_pred_gsearch_SEM)\n",
        "print('Recall: ',knn_recall_gsearch_SEM)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "knn_f1_score_gsearch_SEM = f1_score(y_test, y_pred_gsearch_SEM)\n",
        "print('F1 Score: ',round(knn_f1_score_gsearch_SEM,3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BykHmsDCqfvO"
      },
      "source": [
        "#### Otimizar Hiperparâmetro K utilizando RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HNZp3GHqfvO"
      },
      "source": [
        "# Cronometrar o tempo de execução\n",
        "%%time\n",
        "\n",
        "# Passo 1: Definir a faixa do grid em que o hiperparâmetro vai variar\n",
        "# IMPORTANTE: Formato de 'dictionary' {'label':valor}\n",
        "faixa_K = {'n_neighbors':np.arange(1,20)}\n",
        "niter = 10\n",
        "\n",
        "# Passo 2: Definir o objeto com a técnica e os parâmetros da otimização\n",
        "knn_rsearch_SEM = RandomizedSearchCV(KNeighborsClassifier(),\n",
        "                                     param_distributions=faixa_K,\n",
        "                                     n_iter = niter,\n",
        "                                     cv=5,\n",
        "                                     random_state = 2021)\n",
        "\n",
        "# Passo 3: Otimizar o objeto definido anteriormente no conjunto de dados\n",
        "knn_rsearch_SEM.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Passo 4: Apresentar o melhor K (K quando se obteve o melhor resultado)\n",
        "opt_K = knn_rsearch_SEM.best_params_\n",
        "print(opt_K)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yp76u7gqfvP"
      },
      "source": [
        "# Otimizado o hiperparâmetro\n",
        "%%time\n",
        "# Passo 1: Criar um objeto e ajustar o objeto ao Conjunto de Treino, utilizando o hiperparâmetro ótimo\n",
        "knn_rsearch_SEM = KNeighborsClassifier(n_neighbors=opt_K['n_neighbors']).fit(X_train, y_train)\n",
        "\n",
        "# Passo 2: Fazer predição do modelo no Conjunto de Teste\n",
        "y_pred_rsearch_SEM = knn_rsearch_SEM.predict(X_test)\n",
        "\n",
        "# Passo 3: Avaliar o modelo\n",
        "# Construir Matriz de Confusão (DataFrame)\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_rsearch_SEM, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_rsearch_SEM))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "knn_acc_rsearch_SEM = accuracy_score(y_test, y_pred_rsearch_SEM)\n",
        "print('Acurácia: ',knn_acc_rsearch_SEM)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "knn_prec_rsearch_SEM = precision_score(y_test, y_pred_rsearch_SEM)\n",
        "print('Precisão: ',knn_prec_rsearch_SEM)\n",
        "\n",
        "# Recall (recall_score)\n",
        "knn_recall_rsearch_SEM = recall_score(y_test, y_pred_rsearch_SEM)\n",
        "print('Recall: ',knn_recall_rsearch_SEM)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "knn_f1_score_rsearch_SEM = f1_score(y_test, y_pred_rsearch_SEM)\n",
        "print('F1 Score: ',round(knn_f1_score_rsearch_SEM,3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJErgv1K4q1Z"
      },
      "source": [
        "### 'Dummy' e KNN COM normalização MIN-MAX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbuGE1194yap"
      },
      "source": [
        "# Normalizar Min-Max (Entre 0 e 1). Usar sklearn.preprocessing MinMaxScaler\n",
        "# Fazer a normalização no conjunto de treino (X_train) e usar a mesma 'transformação' no conjunto de teste (X_teste)\n",
        "# Passo 1: Definir o 'scaler' no X_train\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "X_train_norm = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
        "# Passo 2: Usar no X_test a mesma operação feita para a normalização de X_train\n",
        "X_test_norm = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88HM1wSX4q1c"
      },
      "source": [
        "# Criar objeto definindo estratégia para estimativa e ajustar ao conjunto de treino\n",
        "dummy_MinMax = DummyClassifier(strategy='most_frequent').fit(X_train_norm,y_train)\n",
        "\n",
        "# Fazer a predição no conjunto de teste utilizando o objeto definido e ajustado anteriormente\n",
        "y_pred_dummy = dummy_MinMax.predict(X_test_norm)\n",
        "\n",
        "# Construir Matriz de Confusão (DataFrame) para 'Dummy'\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_dummy, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_dummy))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "acc_dummy_MinMax = accuracy_score(y_test, y_pred_dummy)\n",
        "print('Acurácia: ',acc_dummy_MinMax)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "prec_dummy_MinMax = precision_score(y_test, y_pred_dummy)\n",
        "print('Precisão: ',prec_dummy_MinMax)\n",
        "\n",
        "# Recall (recall_score)\n",
        "recall_dummy_MinMax = recall_score(y_test, y_pred_dummy)\n",
        "print('Recall: ',recall_dummy_MinMax)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "f1_score_dummy_MinMax = f1_score(y_test, y_pred_dummy)\n",
        "print('F1 Score: ',round(f1_score_dummy_MinMax,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpmGKjwK4q1f"
      },
      "source": [
        "#### Otimizar Hiperparâmetro K utilizando GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dq4VfkA4q1f"
      },
      "source": [
        "# Cronometrar o tempo de execução\n",
        "%%time\n",
        "\n",
        "# Passo 1: Definir a faixa do grid em que o hiperparâmetro vai variar\n",
        "# IMPORTANTE: Formato de 'dictionary' {'label':valor}\n",
        "faixa_K = {'n_neighbors':np.arange(1,20)}\n",
        "\n",
        "# Passo 2: Definir o objeto com a técnica e os parâmetros da otimização\n",
        "knn_gsearch_MinMax = GridSearchCV(KNeighborsClassifier(),\n",
        "                                  param_grid=faixa_K,\n",
        "                                  cv=5)\n",
        "\n",
        "# Passo 3: Otimizar o objeto definido anteriormente no conjunto de dados\n",
        "knn_gsearch_MinMax.fit(X_train_norm, y_train)\n",
        "\n",
        "\n",
        "# Passo 4: Apresentar o melhor K (K quando se obteve o melhor resultado)\n",
        "opt_K = knn_gsearch_MinMax.best_params_\n",
        "print(opt_K)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PowGSEvi4q1g"
      },
      "source": [
        "# Otimizado o hiperparâmetro\n",
        "%%time\n",
        "# Passo 1: Criar um objeto e ajustar o objeto ao Conjunto de Treino, utilizando o hiperparâmetro ótimo\n",
        "knn_gsearch_MinMax = KNeighborsClassifier(n_neighbors=opt_K['n_neighbors']).fit(X_train_norm, y_train)\n",
        "\n",
        "# Passo 2: Fazer predição do modelo no Conjunto de Teste\n",
        "y_pred_gsearch_MinMax = knn_gsearch_MinMax.predict(X_test_norm)\n",
        "\n",
        "# Passo 3: Avaliar o modelo\n",
        "# Construir Matriz de Confusão (DataFrame)\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_gsearch_MinMax, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_gsearch_MinMax))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "knn_acc_gsearch_MinMax = accuracy_score(y_test, y_pred_gsearch_MinMax)\n",
        "print('Acurácia: ',knn_acc_gsearch_MinMax)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "knn_prec_gsearch_MinMax = precision_score(y_test, y_pred_gsearch_MinMax)\n",
        "print('Precisão: ',knn_prec_gsearch_MinMax)\n",
        "\n",
        "# Recall (recall_score)\n",
        "knn_recall_gsearch_MinMax = recall_score(y_test, y_pred_gsearch_MinMax)\n",
        "print('Recall: ',knn_recall_gsearch_MinMax)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "knn_f1_score_gsearch_MinMax = f1_score(y_test, y_pred_gsearch_MinMax)\n",
        "print('F1 Score: ',round(knn_f1_score_gsearch_MinMax,3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm6RPg3c4q1h"
      },
      "source": [
        "#### Otimizar Hiperparâmetro K utilizando RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Wq5p0Z4q1h"
      },
      "source": [
        "# Cronometrar o tempo de execução\n",
        "%%time\n",
        "\n",
        "# Passo 1: Definir a faixa do grid em que o hiperparâmetro vai variar\n",
        "# IMPORTANTE: Formato de 'dictionary' {'label':valor}\n",
        "faixa_K = {'n_neighbors':np.arange(1,20)}\n",
        "niter = 10\n",
        "\n",
        "# Passo 2: Definir o objeto com a técnica e os parâmetros da otimização\n",
        "knn_rsearch_MinMax = RandomizedSearchCV(KNeighborsClassifier(),\n",
        "                                        param_distributions=faixa_K,\n",
        "                                        n_iter = niter,\n",
        "                                        cv=5,\n",
        "                                        random_state = 2021)\n",
        "\n",
        "# Passo 3: Otimizar o objeto definido anteriormente no conjunto de dados\n",
        "knn_rsearch_MinMax.fit(X_train_norm, y_train)\n",
        "\n",
        "\n",
        "# Passo 4: Apresentar o melhor K (K quando se obteve o melhor resultado)\n",
        "opt_K = knn_rsearch_MinMax.best_params_\n",
        "print(opt_K)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV4y0Wzv4q1h"
      },
      "source": [
        "# Otimizado o hiperparâmetro\n",
        "%%time\n",
        "# Passo 1: Criar um objeto e ajustar o objeto ao Conjunto de Treino, utilizando o hiperparâmetro ótimo\n",
        "knn_rsearch_MinMax = KNeighborsClassifier(n_neighbors=opt_K['n_neighbors']).fit(X_train_norm, y_train)\n",
        "\n",
        "# Passo 2: Fazer predição do modelo no Conjunto de Teste\n",
        "y_pred_rsearch_MinMax = knn_rsearch_MinMax.predict(X_test_norm)\n",
        "\n",
        "# Passo 3: Avaliar o modelo\n",
        "# Construir Matriz de Confusão (DataFrame)\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_rsearch_MinMax, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_rsearch_MinMax))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "knn_acc_rsearch_MinMax = accuracy_score(y_test, y_pred_rsearch_MinMax)\n",
        "print('Acurácia: ',knn_acc_rsearch_MinMax)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "knn_prec_rsearch_MinMax = precision_score(y_test, y_pred_rsearch_MinMax)\n",
        "print('Precisão: ',knn_prec_rsearch_MinMax)\n",
        "\n",
        "# Recall (recall_score)\n",
        "knn_recall_rsearch_MinMax = recall_score(y_test, y_pred_rsearch_MinMax)\n",
        "print('Recall: ',knn_recall_rsearch_MinMax)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "knn_f1_score_rsearch_MinMax = f1_score(y_test, y_pred_rsearch_MinMax)\n",
        "print('F1 Score: ',round(knn_f1_score_rsearch_MinMax,3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KRFKcjK9MMp"
      },
      "source": [
        "### 'Dummy' e KNN COM normalização Z-Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmzkvFth9MMq"
      },
      "source": [
        "# Normalizar Z-Score (Média 0 e Desvio Padrão 1). Usar sklearn.preprocessing StandardScaler\n",
        "# Fazer a normalização no conjunto de treino (X_train) e usar a mesma 'transformação' no conjunto de teste (X_teste)\n",
        "# Passo 1: Definir o 'scaler' no X_train\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_norm = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n",
        "# Passo 2: Usar no X_test a mesma operação feita para a normalização de X_train\n",
        "X_test_norm = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvbKqEwd9MMq"
      },
      "source": [
        "# Criar objeto definindo estratégia para estimativa e ajustar ao conjunto de treino\n",
        "dummy_Z = DummyClassifier(strategy='most_frequent').fit(X_train_norm,y_train)\n",
        "\n",
        "# Fazer a predição no conjunto de teste utilizando o objeto definido e ajustado anteriormente\n",
        "y_pred_dummy = dummy_Z.predict(X_test_norm)\n",
        "\n",
        "# Construir Matriz de Confusão (DataFrame) para 'Dummy'\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_dummy, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_dummy))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "acc_dummy_Z = accuracy_score(y_test, y_pred_dummy)\n",
        "print('Acurácia: ',acc_dummy_Z)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "prec_dummy_Z = precision_score(y_test, y_pred_dummy)\n",
        "print('Precisão: ',prec_dummy_Z)\n",
        "\n",
        "# Recall (recall_score)\n",
        "recall_dummy_Z = recall_score(y_test, y_pred_dummy)\n",
        "print('Recall: ',recall_dummy_Z)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "f1_score_dummy_Z = f1_score(y_test, y_pred_dummy)\n",
        "print('F1 Score: ',round(f1_score_dummy_Z,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TydNEVV1BQ-W"
      },
      "source": [
        "# OBSERVAÇÃO IMPORTANTE!!! \n",
        "# Como pudemos obervar, as métricas para 'Dummy' independem se os dados são normalizados ou não.\n",
        "# 'Dummy', em problemas de CLASSIFICAÇÃO, está relacionado à distribuição dos valores do atributo meta.\n",
        "# Portanto, para facilitar, vamos chamar apenas de _dummy\n",
        "acc_dummy = acc_dummy_Z\n",
        "prec_dummy = prec_dummy_Z\n",
        "recall_dummy = recall_dummy_Z\n",
        "f1_score_dummy = f1_score_dummy_Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhjAv0Tv9MMr"
      },
      "source": [
        "#### Otimizar Hiperparâmetro K utilizando GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQEUjN9Z9MMr"
      },
      "source": [
        "# Cronometrar o tempo de execução\n",
        "%%time\n",
        "\n",
        "# Passo 1: Definir a faixa do grid em que o hiperparâmetro vai variar\n",
        "# IMPORTANTE: Formato de 'dictionary' {'label':valor}\n",
        "faixa_K = {'n_neighbors':np.arange(1,20)}\n",
        "\n",
        "# Passo 2: Definir o objeto com a técnica e os parâmetros da otimização\n",
        "knn_gsearch_Z = GridSearchCV(KNeighborsClassifier(),\n",
        "                             param_grid=faixa_K,\n",
        "                             cv=5)\n",
        "\n",
        "# Passo 3: Otimizar o objeto definido anteriormente no conjunto de dados\n",
        "knn_gsearch_Z.fit(X_train_norm, y_train)\n",
        "\n",
        "\n",
        "# Passo 4: Apresentar o melhor K (K quando se obteve o melhor resultado)\n",
        "opt_K = knn_gsearch_Z.best_params_\n",
        "print(opt_K)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aRKdwRz9MMs"
      },
      "source": [
        "# Otimizado o hiperparâmetro\n",
        "%%time\n",
        "# Passo 1: Criar um objeto e ajustar o objeto ao Conjunto de Treino, utilizando o hiperparâmetro ótimo\n",
        "knn_gsearch_Z = KNeighborsClassifier(n_neighbors=opt_K['n_neighbors']).fit(X_train_norm, y_train)\n",
        "\n",
        "# Passo 2: Fazer predição do modelo no Conjunto de Teste\n",
        "y_pred_gsearch_Z = knn_gsearch_Z.predict(X_test_norm)\n",
        "\n",
        "# Passo 3: Avaliar o modelo\n",
        "# Construir Matriz de Confusão (DataFrame)\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_gsearch_Z, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_gsearch_Z))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "knn_acc_gsearch_Z = accuracy_score(y_test, y_pred_gsearch_Z)\n",
        "print('Acurácia: ',knn_acc_gsearch_Z)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "knn_prec_gsearch_Z = precision_score(y_test, y_pred_gsearch_Z)\n",
        "print('Precisão: ',knn_prec_gsearch_Z)\n",
        "\n",
        "# Recall (recall_score)\n",
        "knn_recall_gsearch_Z = recall_score(y_test, y_pred_gsearch_Z)\n",
        "print('Recall: ',knn_recall_gsearch_Z)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "knn_f1_score_gsearch_Z = f1_score(y_test, y_pred_gsearch_Z)\n",
        "print('F1 Score: ',round(knn_f1_score_gsearch_Z,3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc4hVsHw9MMs"
      },
      "source": [
        "#### Otimizar Hiperparâmetro K utilizando RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OOCEgoG9MMt"
      },
      "source": [
        "# Cronometrar o tempo de execução\n",
        "%%time\n",
        "\n",
        "# Passo 1: Definir a faixa do grid em que o hiperparâmetro vai variar\n",
        "# IMPORTANTE: Formato de 'dictionary' {'label':valor}\n",
        "faixa_K = {'n_neighbors':np.arange(1,20)}\n",
        "niter = 10\n",
        "\n",
        "# Passo 2: Definir o objeto com a técnica e os parâmetros da otimização\n",
        "knn_rsearch_Z = RandomizedSearchCV(KNeighborsClassifier(),\n",
        "                                   param_distributions=faixa_K,\n",
        "                                   n_iter = niter,\n",
        "                                   cv=5,\n",
        "                                   random_state = 2021)\n",
        "\n",
        "# Passo 3: Otimizar o objeto definido anteriormente no conjunto de dados\n",
        "knn_rsearch_Z.fit(X_train_norm, y_train)\n",
        "\n",
        "\n",
        "# Passo 4: Apresentar o melhor K (K quando se obteve o melhor resultado)\n",
        "opt_K = knn_rsearch_Z.best_params_\n",
        "print(opt_K)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g-GLAuV9MMu"
      },
      "source": [
        "# Otimizado o hiperparâmetro\n",
        "%%time\n",
        "# Passo 1: Criar um objeto e ajustar o objeto ao Conjunto de Treino, utilizando o hiperparâmetro ótimo\n",
        "knn_rsearch_Z = KNeighborsClassifier(n_neighbors=opt_K['n_neighbors']).fit(X_train_norm, y_train)\n",
        "\n",
        "# Passo 2: Fazer predição do modelo no Conjunto de Teste\n",
        "y_pred_rsearch_Z = knn_rsearch_Z.predict(X_test_norm)\n",
        "\n",
        "# Passo 3: Avaliar o modelo\n",
        "# Construir Matriz de Confusão (DataFrame)\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_rsearch_Z, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_rsearch_Z))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "knn_acc_rsearch_Z = accuracy_score(y_test, y_pred_rsearch_Z)\n",
        "print('Acurácia: ',knn_acc_rsearch_Z)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "knn_prec_rsearch_Z = precision_score(y_test, y_pred_rsearch_Z)\n",
        "print('Precisão: ',knn_prec_rsearch_Z)\n",
        "\n",
        "# Recall (recall_score)\n",
        "knn_recall_rsearch_Z = recall_score(y_test, y_pred_rsearch_Z)\n",
        "print('Recall: ',knn_recall_rsearch_Z)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "knn_f1_score_rsearch_Z = f1_score(y_test, y_pred_rsearch_Z)\n",
        "print('F1 Score: ',round(knn_f1_score_rsearch_Z,3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wRyeUNLAly1"
      },
      "source": [
        "## ÁRVORE DE DECISÃO\n",
        "\n",
        "* Iremos criar TRÊS modelos:  \n",
        "  (1) SEM normalizar  \n",
        "  (2) Normalizando Min-Max e  \n",
        "  (3) Normalizando Z-Score\n",
        "\n",
        "* Em todos os casos, otimizaremos os hiperparâmetros : max_depth, min_samples_split e min_samples_leaf  \n",
        "  (1) GridSearchCV e  \n",
        "  (2) RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zp9Lh7fAly5"
      },
      "source": [
        "### Árvore de Decisão SEM normalizar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G2G4j5GAly8"
      },
      "source": [
        "#### Otimizar Hiperparâmetros 'max_depth', 'min_samples_split' e 'min_samples_leaf' utilizando GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHJN2sPmAly8"
      },
      "source": [
        "# Cronometrar o tempo de execução\n",
        "%%time\n",
        "\n",
        "# Passo 1: Definir a faixa do grid em que os hiperparâmetros vão variar\n",
        "# IMPORTANTE: Formato de 'dictionary' {'label':valor}\n",
        "# Inicialmente, vamos construir a faixa nos seguinte valores:\n",
        "# max_depth: 2 a 7\n",
        "# min_samples_split: 2 a 11\n",
        "# min_samples_leaf: 2 a 11\n",
        "\n",
        "# OBSERVAÇÃO IMPORTANTE!!!\n",
        "# max_depth (6 valores possíveis), min_samples_split (10 valores possíveis) e min_samples_leaf (10 valores possíveis)\n",
        "# Total de valores possíveis no Grid: 600\n",
        "# Considerando que para cada combinação de valores possíveis, o programa roda 5 vezes (cv=5), para esta faixa, o programa vai ser executado 3000 vezes\n",
        "faixa = \n",
        "\n",
        "# Passo 2: Definir o objeto com a técnica e os parâmetros da otimização\n",
        "arv_gsearch_SEM = \n",
        "\n",
        "# Passo 3: Otimizar o objeto definido anteriormente no conjunto de dados\n",
        "\n",
        "\n",
        "\n",
        "# Passo 4: Apresentar o melhor K (K quando se obteve o melhor resultado)\n",
        "opt_hyp = \n",
        "print(opt_hyp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olyqbrXGAly9"
      },
      "source": [
        "# Otimizado o hiperparâmetro\n",
        "%%time\n",
        "# Passo 1: Criar um objeto e ajustar o objeto ao Conjunto de Treino, utilizando o hiperparâmetro ótimo\n",
        "arv_gsearch_SEM = \n",
        "\n",
        "# Passo 2: Fazer predição do modelo no Conjunto de Teste\n",
        "y_pred_gsearch_SEM = \n",
        "\n",
        "# Passo 3: Avaliar o modelo\n",
        "# Construir Matriz de Confusão (DataFrame)\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_gsearch_SEM, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_gsearch_SEM))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "arv_acc_gsearch_SEM = accuracy_score(y_test, y_pred_gsearch_SEM)\n",
        "print('Acurácia: ',arv_acc_gsearch_SEM)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "arv_prec_gsearch_SEM = precision_score(y_test, y_pred_gsearch_SEM)\n",
        "print('Precisão: ',arv_prec_gsearch_SEM)\n",
        "\n",
        "# Recall (recall_score)\n",
        "arv_recall_gsearch_SEM = recall_score(y_test, y_pred_gsearch_SEM)\n",
        "print('Recall: ',arv_recall_gsearch_SEM)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "arv_f1_score_gsearch_SEM = f1_score(y_test, y_pred_gsearch_SEM)\n",
        "print('F1 Score: ',round(arv_f1_score_gsearch_SEM,3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdDIzU-5Aly-"
      },
      "source": [
        "#### Otimizar Hiperparâmetros 'max_depth', 'min_samples_split' e 'min_samples_leaf' utilizando RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrUt6wwOAly-"
      },
      "source": [
        "# Cronometrar o tempo de execução\n",
        "%%time\n",
        "\n",
        "# Passo 1: Definir a faixa do grid em que os hiperparâmetros vão variar\n",
        "# IMPORTANTE: Formato de 'dictionary' {'label':valor}\n",
        "# Inicialmente, vamos construir a faixa nos seguinte valores:\n",
        "# max_depth: 2 a 16\n",
        "# min_samples_split: 2 a 20, variando de 2 em 2\n",
        "# min_samples_leaf: 2 a 20, variando de 2 em 2\n",
        "\n",
        "# OBSERVAÇÃO IMPORTANTE!!!\n",
        "# max_depth (15 valores possíveis), min_samples_split (10 valores possíveis) e min_samples_leaf (10 valores possíveis)\n",
        "# Total de valores possíveis no Grid: 1500\n",
        "# Escolheremos número de iterações em cerca de 25% a 40% do número total de valores possíveis\n",
        "faixa = \n",
        "\n",
        "niter = \n",
        "\n",
        "# Passo 2: Definir o objeto com a técnica e os parâmetros da otimização\n",
        "arv_rsearch_SEM = \n",
        "\n",
        "# Passo 3: Otimizar o objeto definido anteriormente no conjunto de dados\n",
        "arv_rsearch_SEM.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Passo 4: Apresentar o melhor K (K quando se obteve o melhor resultado)\n",
        "opt_hyp = arv_rsearch_SEM.best_params_\n",
        "print(opt_hyp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQIzATOvAly-"
      },
      "source": [
        "# Otimizado o hiperparâmetro\n",
        "%%time\n",
        "# Passo 1: Criar um objeto e ajustar o objeto ao Conjunto de Treino, utilizando o hiperparâmetro ótimo\n",
        "arv_rsearch_SEM = DecisionTreeClassifier(max_depth=opt_hyp['max_depth'],\n",
        "                                         min_samples_split=opt_hyp['min_samples_split'],\n",
        "                                         min_samples_leaf=opt_hyp['min_samples_leaf']).fit(X_train, y_train)\n",
        "\n",
        "# Passo 2: Fazer predição do modelo no Conjunto de Teste\n",
        "y_pred_rsearch_SEM = arv_rsearch_SEM.predict(X_test)\n",
        "\n",
        "# Passo 3: Avaliar o modelo\n",
        "# Construir Matriz de Confusão (DataFrame)\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_rsearch_SEM, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_rsearch_SEM))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "arv_acc_rsearch_SEM = accuracy_score(y_test, y_pred_rsearch_SEM)\n",
        "print('Acurácia: ',arv_acc_rsearch_SEM)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "arv_prec_rsearch_SEM = precision_score(y_test, y_pred_rsearch_SEM)\n",
        "print('Precisão: ',arv_prec_rsearch_SEM)\n",
        "\n",
        "# Recall (recall_score)\n",
        "arv_recall_rsearch_SEM = recall_score(y_test, y_pred_rsearch_SEM)\n",
        "print('Recall: ',arv_recall_rsearch_SEM)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "arv_f1_score_rsearch_SEM = f1_score(y_test, y_pred_rsearch_SEM)\n",
        "print('F1 Score: ',round(arv_f1_score_rsearch_SEM,3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0ggcEkcVQ9a"
      },
      "source": [
        "### Árvore de Decisão COM normalização MIN-MAX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFAocJOIAlzB"
      },
      "source": [
        "#### Otimizar Hiperparâmetros 'max_depth', 'min_samples_split' e 'min_samples_leaf' utilizando GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtiDtHn7AlzB"
      },
      "source": [
        "# Cronometrar o tempo de execução\n",
        "%%time\n",
        "\n",
        "# Passo 1: Definir a faixa do grid em que o hiperparâmetro vai variar\n",
        "# IMPORTANTE: Formato de 'dictionary' {'label':valor}\n",
        "# Inicialmente, vamos construir a faixa nos seguinte valores:\n",
        "# max_depth: 2 a 7\n",
        "# min_samples_split: 2 a 11\n",
        "# min_samples_leaf: 2 a 11\n",
        "\n",
        "# OBSERVAÇÃO IMPORTANTE!!!\n",
        "# max_depth (6 valores possíveis), min_samples_split (10 valores possíveis) e min_samples_leaf (10 valores possíveis)\n",
        "# Total de valores possíveis no Grid: 600\n",
        "# Considerando que para cada combinação de valores possíveis, o programa roda 5 vezes (cv=5), para esta faixa, o programa vai ser executado 3000 vezes\n",
        "faixa = {'max_depth':np.arange(2,8),\n",
        "         'min_samples_split':np.arange(2,12),\n",
        "         'min_samples_leaf':np.arange(2,12)}\n",
        "\n",
        "# Passo 2: Definir o objeto com a técnica e os parâmetros da otimização\n",
        "arv_gsearch_MinMax = GridSearchCV(DecisionTreeClassifier(),\n",
        "                                  param_grid=faixa,\n",
        "                                  cv=5)\n",
        "\n",
        "# Passo 3: Otimizar o objeto definido anteriormente no conjunto de dados\n",
        "arv_gsearch_MinMax.fit(X_train_norm, y_train)\n",
        "\n",
        "\n",
        "# Passo 4: Apresentar o melhor K (K quando se obteve o melhor resultado)\n",
        "opt_hyp = arv_gsearch_MinMax.best_params_\n",
        "print(opt_hyp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY7vte1sAlzC"
      },
      "source": [
        "# Otimizado o hiperparâmetro\n",
        "%%time\n",
        "# Passo 1: Criar um objeto e ajustar o objeto ao Conjunto de Treino, utilizando o hiperparâmetro ótimo\n",
        "arv_gsearch_MinMax = DecisionTreeClassifier(max_depth=opt_hyp['max_depth'],\n",
        "                                            min_samples_split=opt_hyp['min_samples_split'],\n",
        "                                            min_samples_leaf=opt_hyp['min_samples_leaf']).fit(X_train_norm, y_train)\n",
        "\n",
        "# Passo 2: Fazer predição do modelo no Conjunto de Teste\n",
        "y_pred_gsearch_MinMax = arv_gsearch_MinMax.predict(X_test_norm)\n",
        "\n",
        "# Passo 3: Avaliar o modelo\n",
        "# Construir Matriz de Confusão (DataFrame)\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_gsearch_MinMax, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_gsearch_MinMax))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "arv_acc_gsearch_MinMax = accuracy_score(y_test, y_pred_gsearch_MinMax)\n",
        "print('Acurácia: ',arv_acc_gsearch_MinMax)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "arv_prec_gsearch_MinMax = precision_score(y_test, y_pred_gsearch_MinMax)\n",
        "print('Precisão: ',arv_prec_gsearch_MinMax)\n",
        "\n",
        "# Recall (recall_score)\n",
        "arv_recall_gsearch_MinMax = recall_score(y_test, y_pred_gsearch_MinMax)\n",
        "print('Recall: ',arv_recall_gsearch_MinMax)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "arv_f1_score_gsearch_MinMax = f1_score(y_test, y_pred_gsearch_MinMax)\n",
        "print('F1 Score: ',round(arv_f1_score_gsearch_MinMax,3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75OvkOkHAlzC"
      },
      "source": [
        "#### Otimizar Hiperparâmetros 'max_depth', 'min_samples_split' e 'min_samples_leaf' utilizando RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kzBict5AlzC"
      },
      "source": [
        "# Cronometrar o tempo de execução\n",
        "%%time\n",
        "\n",
        "# Passo 1: Definir a faixa do grid em que o hiperparâmetro vai variar\n",
        "# IMPORTANTE: Formato de 'dictionary' {'label':valor}\n",
        "# Inicialmente, vamos construir a faixa nos seguinte valores:\n",
        "# max_depth: 2 a 16\n",
        "# min_samples_split: 2 a 20, variando de 2 em 2\n",
        "# min_samples_leaf: 2 a 20, variando de 2 em 2\n",
        "\n",
        "# OBSERVAÇÃO IMPORTANTE!!!\n",
        "# max_depth (15 valores possíveis), min_samples_split (10 valores possíveis) e min_samples_leaf (10 valores possíveis)\n",
        "# Total de valores possíveis no Grid: 1500\n",
        "# Escolheremos número de iterações em cerca de 25% a 40% do número total de valores possíveis\n",
        "faixa = {'max_depth':np.arange(2,17),\n",
        "         'min_samples_split':np.arange(2,21,2),\n",
        "         'min_samples_leaf':np.arange(2,21,2)}\n",
        "niter = 450\n",
        "\n",
        "# Passo 2: Definir o objeto com a técnica e os parâmetros da otimização\n",
        "arv_rsearch_MinMax = RandomizedSearchCV(DecisionTreeClassifier(),\n",
        "                                        param_distributions=faixa,\n",
        "                                        n_iter = niter,\n",
        "                                        cv=5,\n",
        "                                        random_state = 2021)\n",
        "\n",
        "# Passo 3: Otimizar o objeto definido anteriormente no conjunto de dados\n",
        "arv_rsearch_MinMax.fit(X_train_norm, y_train)\n",
        "\n",
        "\n",
        "# Passo 4: Apresentar o melhor K (K quando se obteve o melhor resultado)\n",
        "opt_hyp = arv_rsearch_MinMax.best_params_\n",
        "print(opt_hyp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7seyc_HEAlzC"
      },
      "source": [
        "# Otimizado o hiperparâmetro\n",
        "%%time\n",
        "# Passo 1: Criar um objeto e ajustar o objeto ao Conjunto de Treino, utilizando o hiperparâmetro ótimo\n",
        "arv_rsearch_MinMax = DecisionTreeClassifier(max_depth=opt_hyp['max_depth'],\n",
        "                                              min_samples_split=opt_hyp['min_samples_split'],\n",
        "                                              min_samples_leaf=opt_hyp['min_samples_leaf']).fit(X_train_norm, y_train)\n",
        "\n",
        "# Passo 2: Fazer predição do modelo no Conjunto de Teste\n",
        "y_pred_rsearch_MinMax = arv_rsearch_MinMax.predict(X_test_norm)\n",
        "\n",
        "# Passo 3: Avaliar o modelo\n",
        "# Construir Matriz de Confusão (DataFrame)\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_rsearch_MinMax, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_rsearch_MinMax))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "arv_acc_rsearch_MinMax = accuracy_score(y_test, y_pred_rsearch_MinMax)\n",
        "print('Acurácia: ',arv_acc_rsearch_MinMax)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "arv_prec_rsearch_MinMax = precision_score(y_test, y_pred_rsearch_MinMax)\n",
        "print('Precisão: ',arv_prec_rsearch_MinMax)\n",
        "\n",
        "# Recall (recall_score)\n",
        "arv_recall_rsearch_MinMax = recall_score(y_test, y_pred_rsearch_MinMax)\n",
        "print('Recall: ',arv_recall_rsearch_MinMax)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "arv_f1_score_rsearch_MinMax = f1_score(y_test, y_pred_rsearch_MinMax)\n",
        "print('F1 Score: ',round(arv_f1_score_rsearch_MinMax,3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKUH27GhZUBN"
      },
      "source": [
        "### Árvore de Decisão COM normalização Z-Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GCCZsuqAlzD"
      },
      "source": [
        "#### Otimizar Hiperparâmetros 'max_depth', 'min_samples_split' e 'min_samples_leaf' utilizando GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F_H4jjcAlzE"
      },
      "source": [
        "# Cronometrar o tempo de execução\n",
        "%%time\n",
        "\n",
        "# Passo 1: Definir a faixa do grid em que o hiperparâmetro vai variar\n",
        "# IMPORTANTE: Formato de 'dictionary' {'label':valor}\n",
        "# Inicialmente, vamos construir a faixa nos seguinte valores:\n",
        "# max_depth: 2 a 7\n",
        "# min_samples_split: 2 a 11\n",
        "# min_samples_leaf: 2 a 11\n",
        "\n",
        "# OBSERVAÇÃO IMPORTANTE!!!\n",
        "# max_depth (6 valores possíveis), min_samples_split (10 valores possíveis) e min_samples_leaf (10 valores possíveis)\n",
        "# Total de valores possíveis no Grid: 600\n",
        "# Considerando que para cada combinação de valores possíveis, o programa roda 5 vezes (cv=5), para esta faixa, o programa vai ser executado 3000 vezes\n",
        "faixa = {'max_depth':np.arange(2,8),\n",
        "         'min_samples_split':np.arange(2,12),\n",
        "         'min_samples_leaf':np.arange(2,12)}\n",
        "\n",
        "# Passo 2: Definir o objeto com a técnica e os parâmetros da otimização\n",
        "arv_gsearch_Z = GridSearchCV(DecisionTreeClassifier(),\n",
        "                             param_grid=faixa,\n",
        "                             cv=5)\n",
        "\n",
        "# Passo 3: Otimizar o objeto definido anteriormente no conjunto de dados\n",
        "arv_gsearch_Z.fit(X_train_norm, y_train)\n",
        "\n",
        "\n",
        "# Passo 4: Apresentar o melhor K (K quando se obteve o melhor resultado)\n",
        "opt_hyp = arv_gsearch_Z.best_params_\n",
        "print(opt_hyp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktKQqo2-AlzE"
      },
      "source": [
        "# Otimizado o hiperparâmetro\n",
        "%%time\n",
        "# Passo 1: Criar um objeto e ajustar o objeto ao Conjunto de Treino, utilizando o hiperparâmetro ótimo\n",
        "arv_gsearch_Z = DecisionTreeClassifier(max_depth=opt_hyp['max_depth'],\n",
        "                                       min_samples_split=opt_hyp['min_samples_split'],\n",
        "                                       min_samples_leaf=opt_hyp['min_samples_leaf']).fit(X_train_norm, y_train)\n",
        "\n",
        "# Passo 2: Fazer predição do modelo no Conjunto de Teste\n",
        "y_pred_gsearch_Z = arv_gsearch_Z.predict(X_test_norm)\n",
        "\n",
        "# Passo 3: Avaliar o modelo\n",
        "# Construir Matriz de Confusão (DataFrame)\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_gsearch_Z, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_gsearch_Z))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "arv_acc_gsearch_Z = accuracy_score(y_test, y_pred_gsearch_Z)\n",
        "print('Acurácia: ',arv_acc_gsearch_Z)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "arv_prec_gsearch_Z = precision_score(y_test, y_pred_gsearch_Z)\n",
        "print('Precisão: ',arv_prec_gsearch_Z)\n",
        "\n",
        "# Recall (recall_score)\n",
        "arv_recall_gsearch_Z = recall_score(y_test, y_pred_gsearch_Z)\n",
        "print('Recall: ',arv_recall_gsearch_Z)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "arv_f1_score_gsearch_Z = f1_score(y_test, y_pred_gsearch_Z)\n",
        "print('F1 Score: ',round(arv_f1_score_gsearch_Z,3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XToEauEtAlzF"
      },
      "source": [
        "#### Otimizar Hiperparâmetros 'max_depth', 'min_samples_split' e 'min_samples_leaf' utilizando RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYvVshltAlzF"
      },
      "source": [
        "# Cronometrar o tempo de execução\n",
        "%%time\n",
        "\n",
        "# Passo 1: Definir a faixa do grid em que o hiperparâmetro vai variar\n",
        "# IMPORTANTE: Formato de 'dictionary' {'label':valor}\n",
        "# Inicialmente, vamos construir a faixa nos seguinte valores:\n",
        "# max_depth: 2 a 16\n",
        "# min_samples_split: 2 a 20, variando de 2 em 2\n",
        "# min_samples_leaf: 2 a 20, variando de 2 em 2\n",
        "\n",
        "# OBSERVAÇÃO IMPORTANTE!!!\n",
        "# max_depth (15 valores possíveis), min_samples_split (10 valores possíveis) e min_samples_leaf (10 valores possíveis)\n",
        "# Total de valores possíveis no Grid: 1500\n",
        "# Escolheremos número de iterações em cerca de 25% a 40% do número total de valores possíveis\n",
        "faixa = {'max_depth':np.arange(2,17),\n",
        "         'min_samples_split':np.arange(2,21,2),\n",
        "         'min_samples_leaf':np.arange(2,21,2)}\n",
        "niter = 450\n",
        "\n",
        "# Passo 2: Definir o objeto com a técnica e os parâmetros da otimização\n",
        "arv_rsearch_Z = RandomizedSearchCV(DecisionTreeClassifier(),\n",
        "                                   param_distributions=faixa,\n",
        "                                   n_iter = niter,\n",
        "                                   cv=5,\n",
        "                                   random_state = 2021)\n",
        "\n",
        "# Passo 3: Otimizar o objeto definido anteriormente no conjunto de dados\n",
        "arv_rsearch_Z.fit(X_train_norm, y_train)\n",
        "\n",
        "\n",
        "# Passo 4: Apresentar o melhor K (K quando se obteve o melhor resultado)\n",
        "opt_hyp = arv_rsearch_Z.best_params_\n",
        "print(opt_hyp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mPrjD0dAlzF"
      },
      "source": [
        "# Otimizado o hiperparâmetro\n",
        "%%time\n",
        "# Passo 1: Criar um objeto e ajustar o objeto ao Conjunto de Treino, utilizando o hiperparâmetro ótimo\n",
        "arv_rsearch_Z = DecisionTreeClassifier(max_depth=opt_hyp['max_depth'],\n",
        "                                       min_samples_split=opt_hyp['min_samples_split'],\n",
        "                                       min_samples_leaf=opt_hyp['min_samples_leaf']).fit(X_train_norm, y_train)\n",
        "\n",
        "# Passo 2: Fazer predição do modelo no Conjunto de Teste\n",
        "y_pred_rsearch_Z = arv_rsearch_Z.predict(X_test_norm)\n",
        "\n",
        "# Passo 3: Avaliar o modelo\n",
        "# Construir Matriz de Confusão (DataFrame)\n",
        "MatConf = pd.DataFrame(confusion_matrix(y_test, y_pred_rsearch_Z, labels=[0,1]),\n",
        "                       index=['obs 0', 'obs 1'],columns=['pred 0', 'pred 1'])\n",
        "\n",
        "print(MatConf)\n",
        "\n",
        "# Apresentar as métricas usando 'classification_report'\n",
        "print(classification_report(y_test, y_pred_rsearch_Z))\n",
        "\n",
        "# Calcular individualmente os valores de Acurácia, Precisão, Recall e F1-score\n",
        "\n",
        "# Acurácia (accuracy_score)\n",
        "arv_acc_rsearch_Z = accuracy_score(y_test, y_pred_rsearch_Z)\n",
        "print('Acurácia: ',arv_acc_rsearch_Z)\n",
        "\n",
        "# Precisão (precision_score)\n",
        "arv_prec_rsearch_Z = precision_score(y_test, y_pred_rsearch_Z)\n",
        "print('Precisão: ',arv_prec_rsearch_Z)\n",
        "\n",
        "# Recall (recall_score)\n",
        "arv_recall_rsearch_Z = recall_score(y_test, y_pred_rsearch_Z)\n",
        "print('Recall: ',arv_recall_rsearch_Z)\n",
        "\n",
        "# F1-Score (f1_score)\n",
        "arv_f1_score_rsearch_Z = f1_score(y_test, y_pred_rsearch_Z)\n",
        "print('F1 Score: ',round(arv_f1_score_rsearch_Z,3))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD-lGMZVcspt"
      },
      "source": [
        "### Desenhando um Árvore de Decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HopEy9ttppgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "5cdd03b5-13ee-4121-a738-70d1f9eec676"
      },
      "source": [
        "# Desenhando a Árvore de Decisão\n",
        "plot.tree(arv_rsearch_Z);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-957472be62f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Desenhando a Árvore de Decisão\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marv_rsearch_Z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plot' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BImUm_3MdA9p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6a674a5e-a2ad-45e6-a5b7-495eaeac8f67"
      },
      "source": [
        "# Desenhar a Árvore de Decisão UM POUCO MAIOR\n",
        "plt.figure(figsize=(20,15))\n",
        "plot.tree(arv_rsearch_Z);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5355af2b6338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Desenhar a Árvore de Decisão UM POUCO MAIOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marv_rsearch_Z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plot' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1080 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6d6JRkafMcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ef419323-cd94-49a4-e638-cef003a2f70b"
      },
      "source": [
        "# Aumentar o tamanho da figura e da fonte\n",
        "plt.figure(figsize=(15,10))\n",
        "plot.tree(arv_rsearch_Z, fontsize=10, max_depth=4);"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-403208c364a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Aumentar o tamanho da figura e da fonte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marv_rsearch_Z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plot' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1080 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzWidwkEf4WF"
      },
      "source": [
        "# Dar nomes aos atributos\n",
        "plt.figure(figsize=(15,10))\n",
        "plot.tree(arv_rsearch_Z, \n",
        "          fontsize=10, \n",
        "          max_depth=4,  # se tirar esse linha, ele vai até embaixo\n",
        "          feature_names=X_test.columns);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g59gB9pWdNnO"
      },
      "source": [
        "# Dar nomes às classes\n",
        "plt.figure(figsize=(15,10))\n",
        "plot.tree(arv_rsearch_Z, \n",
        "          fontsize=10, \n",
        "          max_depth=4,  # se tirar esse linha, ele vai até embaixo\n",
        "          feature_names=X_test.columns,\n",
        "          class_names=['0', '1']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co-I49PxgKM1"
      },
      "source": [
        "# Dar cor às classes\n",
        "plt.figure(figsize=(15,10))\n",
        "plot.tree(arv_rsearch_Z, \n",
        "          fontsize=10, \n",
        "          max_depth=4,  # se tirar esse linha, ele vai até embaixo\n",
        "          feature_names=X_test.columns,\n",
        "          class_names=['0', '1'],\n",
        "          filled = True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq9xe-byh7ot"
      },
      "source": [
        "# Salvar a figura\n",
        "    plt.figure(figsize=(15,10))\n",
        "plot.tree(arv_rsearch_Z, \n",
        "          fontsize=10, \n",
        "          max_depth=4,  # se tirar esse linha, ele vai até embaixo\n",
        "          feature_names=X_test.columns,\n",
        "          class_names=['0', '1'],\n",
        "          filled = True);\n",
        "\n",
        "plt.savefig('Arv.png')            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW8Ie-gpj01g"
      },
      "source": [
        "# Comparação dos resultados obtidos com os modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz_giRQNmZLW"
      },
      "source": [
        "## Acurácia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_ftRqoPiMBl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a57d6a60-9eed-4cd1-a75a-3e4cdaa6dc1d"
      },
      "source": [
        "acc = [acc_dummy, \n",
        "       knn_acc_gsearch_SEM, knn_acc_rsearch_SEM, \n",
        "       knn_acc_gsearch_MinMax, knn_acc_rsearch_MinMax,\n",
        "       knn_acc_gsearch_Z, knn_acc_rsearch_Z,\n",
        "       arv_acc_gsearch_SEM, arv_acc_rsearch_SEM,\n",
        "       arv_acc_gsearch_MinMax, arv_acc_rsearch_MinMax,\n",
        "       arv_acc_gsearch_Z, arv_acc_rsearch_Z]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-aad0ef028cf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m acc = [acc_dummy, \n\u001b[0m\u001b[1;32m      2\u001b[0m        \u001b[0mknn_acc_gsearch_SEM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_acc_rsearch_SEM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m        \u001b[0mknn_acc_gsearch_MinMax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_acc_rsearch_MinMax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0mknn_acc_gsearch_Z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_acc_rsearch_Z\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0marv_acc_gsearch_SEM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marv_acc_rsearch_SEM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'acc_dummy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9sRYlgqt-92"
      },
      "source": [
        "## Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEPVeGG_uAM-"
      },
      "source": [
        "prec = [prec_dummy,\n",
        "        knn_prec_gsearch_SEM, knn_prec_rsearch_SEM,\n",
        "        knn_prec_gsearch_MinMax, knn_prec_rsearch_MinMax,\n",
        "        knn_prec_gsearch_Z, knn_prec_rsearch_Z,\n",
        "        arv_prec_gsearch_SEM, arv_prec_rsearch_SEM,\n",
        "        arv_prec_gsearch_MinMax, arv_prec_rsearch_MinMax,\n",
        "        arv_prec_gsearch_Z, arv_prec_rsearch_Z]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn2qSnfut5Dh"
      },
      "source": [
        "## Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNsm_iJbt7Hv"
      },
      "source": [
        "recall = [recall_dummy,\n",
        "          knn_recall_gsearch_SEM, knn_recall_rsearch_SEM,\n",
        "          knn_recall_gsearch_MinMax, knn_recall_rsearch_MinMax,\n",
        "          knn_recall_gsearch_Z, knn_recall_rsearch_Z,\n",
        "          arv_recall_gsearch_SEM, arv_recall_rsearch_SEM,\n",
        "          arv_recall_gsearch_MinMax, arv_recall_rsearch_MinMax,\n",
        "          arv_recall_gsearch_Z, arv_recall_rsearch_Z]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRMaQnlCuENz"
      },
      "source": [
        "## F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gmzCqDuuGVw"
      },
      "source": [
        "f1_score = [f1_score_dummy,\n",
        "            knn_f1_score_gsearch_SEM, knn_f1_score_rsearch_SEM,\n",
        "            knn_f1_score_gsearch_MinMax, knn_f1_score_rsearch_MinMax,\n",
        "            knn_f1_score_gsearch_Z, knn_f1_score_rsearch_Z,\n",
        "            arv_f1_score_gsearch_SEM, arv_f1_score_rsearch_SEM,\n",
        "            arv_f1_score_gsearch_MinMax, arv_f1_score_rsearch_MinMax,\n",
        "            arv_f1_score_gsearch_Z, arv_f1_score_rsearch_Z]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxFBokg9vYFO"
      },
      "source": [
        "## Construir DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqwFjb1ov5Yz"
      },
      "source": [
        "df_metricas = pd.DataFrame([acc,prec,recall,f1_score],\n",
        "                           columns=['Dummy','KNN_GSEM','KNN_RSEM','KNN_GMinMax','KNN_RMinMax','KNN_GZ','KNN_RZ','Arv_GSEM','Arv_RSEM','Arv_GMinMax','Arv_RMinMax','Arv_GZ','Arv_RZ'],\n",
        "                           index=['Acc','Prec','Recall','F1-Score'])\n",
        "\n",
        "df_metricas.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWiCmlHZv8nd"
      },
      "source": [
        "# o grid search garante ótimos melhores (ele faz ponto por ponto)\n",
        "# o randomized trabalha com intervalos maiores e faço algumas alterações\n",
        "# Transpor a matriz (Colunas virarem linhas e Linhas virarem colunas)\n",
        "df_metricas = df_metricas.T\n",
        "df_metricas.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKZ-0ISqXNpo"
      },
      "source": [
        "# Gráfico da Acurácia de todos os modelos\n",
        "#df_metricas['Acc'].plot(kind=\"bar\", ylim = [0.5,0.8], title='Acurácia', figsize=(12,6));\n",
        "df_metricas['Acc'].plot.bar(ylim = [0.5, 0.75], title = 'Acurácia', figsize = (12,6));\n",
        "# árvore não é sensível a normalização (ela compara o atributo com ele mesmo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D78ofkLGu_uh"
      },
      "source": [
        "# Gráfico da Precisão de todos os modelos\n",
        "df_metricas['Prec'].plot.bar(ylim = [0.5, 0.75], title = 'Precisão', figsize = (12,6));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTI2CNQW4dOq"
      },
      "source": [
        "# Gráfico do Recall de todos os modelos\n",
        "# o dummy fica muito melhor, o KNN sem normalização fica melhor que normalizado\n",
        "df_metricas['Recall'].plot.bar(ylim = [0.6,0.8], title = 'Recall', figsize = (12,6));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CszKHJCg5DyC"
      },
      "source": [
        "# Gráfico do F1-Score de todos os modelos\n",
        "df_metricas['F1-Score'].plot.bar(ylim = [0.65, 0.77], title = 'F1-Score', figsize = (12,6));"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}